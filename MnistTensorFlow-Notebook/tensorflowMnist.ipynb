{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logos.jpg\" width=\"700\" />\n",
    "\n",
    "# Tensorflow example using Mnist dataset\n",
    "\n",
    "The purpose of this notebook is to ilustrate the use of __Tensorflow__ package in an example that includes the construction of a neural network and the use of a supervised learning approach based in the back-propagation theory. The proposed example is based on the classic Mnist dataset in which the main objective is to identify images of hand-written digits.\n",
    "\n",
    "Example main features:\n",
    "\n",
    "1. All the code was implemented in Python 3.5 https://www.python.org/ \n",
    "2. The  Python packages required to run the programs are the following:\n",
    "    * Jupyter notebook (Python interactive prompt) http://jupyter.org/index.html\n",
    "    * Tensorflow (Representation-classification) https://www.tensorflow.org/\n",
    "    * Numpy (classification) http://www.numpy.org/\n",
    "    * Matplotlib (visualization) https://matplotlib.org/\n",
    "3. The Tensorflow version used correspond to a standalone application which means that does not support the use of parallel \n",
    "   computations on GPUs.\n",
    "\n",
    "    \n",
    "## Step 1: Load the MNIST dataset\n",
    "\n",
    "The Mnist dataset includes over 60,000 training images, plus 10,000 test images resized into 28x28 matices with grayscale values between 0 and 254.The following shows how to load this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 7 , 3 , 4 , 6 , 1 , 8 , 1 , 0 , 9 , 8\n"
     ]
    }
   ],
   "source": [
    "#Command used to see the plot inside the Jupyter notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Package used to get the Mnist dataset from Tensorflow available examples\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#Load the Mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "labels=[]\n",
    "#Plot the first ten images of the Mnist dataset\n",
    "for number in range(10):\n",
    "    #Add a subplot to the matplotlib main canvas\n",
    "    plt.subplot(1,10,number+1)\n",
    "    #Get images and labels from the dataset\n",
    "    image=mnist.train.images[number]\n",
    "    label=mnist.train.labels[number]\n",
    "    #Transform the image to a numpy object to manipulate it\n",
    "    image=np.array(image, dtype='float')\n",
    "    #Reshape(rows,columns) the digits from a matrix of (784,) to a matrix of (28,28)\n",
    "    plt.imshow(image.reshape(28, 28), cmap='Greys_r')\n",
    "    #Eliminate axis labels from the plot\n",
    "    plt.axis('off')\n",
    "    labels.append(label)\n",
    "#Show the plot (ten images)    \n",
    "plt.show()\n",
    "#Transform the labels to a single number instead of a list\n",
    "labels=[str([i for i,y in enumerate(x) if y == 1][0]) for x in labels]\n",
    "print (\"Labels: \"+\" , \".join(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the Mnist dataset\n",
    "1. Cast the digits from each training image to a float number (in case of any error in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped image examples\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Reshaped label examples\n",
      "[7 3 4 6 1 8 1 0 9 8]\n",
      "Images dimensions: (55000, 784)\n",
      "Labels dimensions: (55000, 784)\n"
     ]
    }
   ],
   "source": [
    "#Empty lists for storing reshaped images and labels\n",
    "trainingImages= []\n",
    "trainingLabels=[]\n",
    "#For each image\n",
    "for image in mnist.train.images:\n",
    "    #Transform all the values to a float data type\n",
    "    image=np.array(image, dtype='float')\n",
    "    #Transform an image to a matrix of 28x28\n",
    "    trainingImages.append(image)\n",
    "#Obtain the labels associated to each image (in a scalar form instead of a vector)\n",
    "for label in mnist.train.labels:   \n",
    "    trainingLabels.append(str([i for i,y in enumerate(label) if y == 1][0]))\n",
    "#Transform the training list to a numpy array (for compatibility with Tensorflow function)   \n",
    "trainingImages = np.array(trainingImages, np.float32)    \n",
    "trainingLabels = np.array(trainingLabels, np.int32) \n",
    "print (\"Reshaped image examples\")\n",
    "print(trainingImages[:10])\n",
    "print (\"Reshaped label examples\")\n",
    "print(trainingLabels[:10])\n",
    "print (\"Images dimensions: \" + str(trainingImages.shape))\n",
    "print (\"Labels dimensions: \" + str(trainingImages.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Reshape the digits from each test image to a matrix of (28,28) (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages= []\n",
    "testLabels=[]\n",
    "for image in mnist.test.images:\n",
    "    image=np.array(image, dtype='float')\n",
    "    testImages.append(image)   \n",
    "for label in mnist.test.labels:   \n",
    "    testLabels.append(str([i for i,y in enumerate(label) if y == 1][0]))  \n",
    "testImages = np.array(testImages, np.float32)    \n",
    "testLabels = np.array(testLabels, np.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Tensorflow graph \n",
    "\n",
    "1. Remainder of the Back-propagtion intuition\n",
    "\n",
    "<img src=\"backPropagation.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "2\\.  Multi-layer perceptron proposed for this example\n",
    "\n",
    "<img src=\"backPropagation2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\.  Create the proposed graph in the Tensorflow environment considering that nodes in the graph represent mathematical operations, whereas edges represent data (tensors) that is communicated from one node to others. It is important to highlight that tensors are multidimensional arrays (representing vectors with a 1D tensors, matrices with a 2D tensors, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Number of neurons for the input layer\n",
    "n_inputs = 28*28 #Features size\n",
    "#Number of neurons per hidden layer\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 300\n",
    "n_hidden3 = 100\n",
    "#Number of neurons for the output layer\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the graph construction, a placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/placeholder\n",
    "#Training sample representation\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")  #2D tensor\n",
    "#Target sample representation\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") #1D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After define the placeholders, we can create a function that represents the behavior of a neural network layer. It is important to noticed that in the function there are define multiple Tensorflow variables which helps to represent shared, persistent values across a graph execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function parameters:\n",
    "\n",
    "X = Vector features (28x28)\n",
    "n_neurons = Number of neurons for a layer\n",
    "name= Layer name\n",
    "activation = Activation functions used for each neuron\n",
    "\"\"\"\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    #Tensorflow name scope to group together operations (nodes) in the graph\n",
    "    with tf.name_scope(name):\n",
    "        #Get the number of elements by checking the vectors feature shape\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        #Create a random weight matrix using a Gaussian distribution\n",
    "        #The standard deviation helps the algorithm to converge faster in a training phase\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        #Create a Tensorflow variable for the bias\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        \n",
    "        \"\"\"\n",
    "        ATTENTION: Creation of the graph in Tensorflow\n",
    "        Compute the weighted sum of the inputs plus the bias term for each neuron the layer\n",
    "        https://www.tensorflow.org/api_docs/python/tf/matmul\n",
    "        \"\"\"\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        #Returns the activation function of each neuron in the layer\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the different layers are created in the graph (neural network) using the previously created function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow name scope to group together operations (nodes) in the graph\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    # The first layer take the feature vector as input\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",activation=tf.nn.relu)\n",
    "    #The second layer take the output of the first layer as input\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",activation=tf.nn.relu)\n",
    "    #The third layer take the output of the second layer as input\n",
    "    hidden3 = neuron_layer(hidden2, n_hidden3, name=\"hidden3\",activation=tf.nn.relu)\n",
    "    #The output of the third layer is taken as input for the final layer\n",
    "    #Outputs are also called logits in the neural network theory\n",
    "    ouputs = neuron_layer(hidden3, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function used in the neural network is presented below (https://www.tensorflow.org/versions/r1.0/api_guides/python/nn):\n",
    "\n",
    "<img src=\"ReLU.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a cost function and optimizer for the Tensorflow graph\n",
    "\n",
    "1. Define a cost function that helps to obtain the error rate between the neural network output and the real value provided by the training labels. In this case the __softmax cross entropy__ is used, considering that this function penalize models that estimate a low probability for the target labels. The softmax cross entropy function first apply the softmax activation and then compute the cross entropy. In order to obtain the error rate (single value) associated, the __mean cross entropy__ is obtained.\n",
    "\n",
    "<img src=\"cost.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"softmaxFun.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"crossEntropy.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cost\"):\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits\n",
    "    #Obtain the softmax cross entropy which returns a ID tensor\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=ouputs)\n",
    "    #Obtain the mean value associated to the 1D tensor previously calculated\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/reduce_mean\n",
    "    loss = tf.reduce_mean(entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. After obtaining the error rate associated to the graph we need to minimize the cost function by updating the graph weights using an optimization process. In this case it is use a gradient descent approach considering its versatility to be applied to different types of problems.\n",
    "\n",
    "<img src=\"gradient.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the Learning step is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the \n",
    "loss gradient. The lower the value, the slower we travel along the downward slope\n",
    "\"\"\"\n",
    "learningStep = 0.01\n",
    "#Tensorflow name scope to group together operations (nodes) in the graph\n",
    "with tf.name_scope(\"train\"):\n",
    "    #Prepare the optimizer\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learningStep)\n",
    "    #Minimize the error rate\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Training phase\n",
    "\n",
    "1. Specify how to evaluate  the model that is going to be created from the neural network. First, for each instance, determine if the neural networks prediction is correct by checking whether or not the highest value obtained in the output layer correspond to the target label. Later calculate the average of the results obtained and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"evaluation\"):\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k\n",
    "    #Says whether the targets are in the top K predictions.\n",
    "    correct = tf.nn.in_top_k(ouputs, y, 1)\n",
    "    #Obtain the accuracy for each training vector\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/cast\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Implement a function that divides the training dataset into a number of sets or parts for creating the neural network easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatch(X, y, batch_size):\n",
    "    #Obtan a list of random indices from 0 to len(X)\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    #Split a list into multiple sub-arrays.\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        #Obtain the list batches\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        #Return a Python generator that creates the batches on the fly without saving them in memory\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. After the construction of the graph structure and the operations associated, the next step is to create a classification model following a supervised learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', 1, 'Batch accuracy:', 0.96)\n",
      "('Epoch:', 2, 'Batch accuracy:', 0.88)\n",
      "('Epoch:', 3, 'Batch accuracy:', 0.98)\n",
      "('Epoch:', 4, 'Batch accuracy:', 0.98)\n",
      "('Epoch:', 5, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 6, 'Batch accuracy:', 0.96)\n",
      "('Epoch:', 7, 'Batch accuracy:', 0.98)\n",
      "('Epoch:', 8, 'Batch accuracy:', 0.98)\n",
      "('Epoch:', 9, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 10, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 11, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 12, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 13, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 14, 'Batch accuracy:', 1.0)\n",
      "('Epoch:', 15, 'Batch accuracy:', 0.98)\n"
     ]
    }
   ],
   "source": [
    "#Allocate all the variables in the Tensorflow environment for initialization\n",
    "#https://www.tensorflow.org/api_docs/python/tf/global_variables\n",
    "init = tf.global_variables_initializer()\n",
    "#Tensorflow variable used for saving (and restoring) our model to disk\n",
    "#https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "saver = tf.train.Saver()\n",
    "#Number of epochs that we want to run the model\n",
    "numberEpochs = 15\n",
    "#Number of batches related to each epoch\n",
    "batchSize = 50\n",
    "\"\"\"\n",
    "Create a TensorFlow session to run the graph across a set of local and remote devices. A Session object \n",
    "encapsulates the environment in which Operation objects are executed, and tensor objects are evaluated.\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    #Initialize all variables in the session\n",
    "    init.run()\n",
    "    #One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n",
    "    for epoch in range(numberEpochs):\n",
    "        #Since, one epoch is too big to feed to the computer at once we divide it in several smaller batches.\n",
    "        for X_batch, y_batch in createBatch(trainingImages, trainingLabels, batchSize):\n",
    "            #Train the neural network using each batch \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        #Evaluate the accuracy for each batch    \n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})   \n",
    "        print(\"Epoch:\",epoch+1, \"Batch accuracy:\", acc_batch)\n",
    "    #Save the model in the disk for evaluation later the test dataset  \n",
    "    save_path = saver.save(sess, \"./NeuralNetworkModel.ckpt\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test phase\n",
    "\n",
    "- Evaluate the proposed model with the Mnist test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./NeuralNetworkModel.ckpt\n",
      "('Predicted classes:', array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]))\n",
      "('Actual classes:   ', array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4],\n",
      "      dtype=int32))\n",
      "('Accuracy prediction:', 0.98)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a TensorFlow session to run the graph across a set of local and remote devices. A Session object \n",
    "encapsulates the environment in which Operation objects are executed, and tensor objects are evaluated.\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    #Recover the model from the disk\n",
    "    saver.restore(sess, \"./NeuralNetworkModel.ckpt\")\n",
    "    #Obtain the first twenty images from the test dataset\n",
    "    testSubset = testImages[:20]\n",
    "    #Apply the model for each image to obtain a prediction (number label)\n",
    "    Z = ouputs.eval(feed_dict={X:testSubset})\n",
    "    #Obtain the index of the maximum value of the ten neurons in the ouput layer\n",
    "    predictions = np.argmax(Z, axis=1)\n",
    "    #Show a comparison of predicted values and true values (gold standard)\n",
    "    print(\"Predicted classes:\", predictions)\n",
    "    print(\"Actual classes:   \", testLabels[:20])  \n",
    "    accuracyPrediction = accuracy.eval(feed_dict={X: X_batch, y: y_batch})   \n",
    "    print(\"Accuracy prediction:\", accuracyPrediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- What we seen so far:\n",
    "    1. Load and inspect an specific dataset.\n",
    "    2. Preprocess the information associated to the dataset.\n",
    "    3. Creation of a Neural network using the Tensorflow package.\n",
    "        * Input layer with seven hundred and eighty four neurons.\n",
    "        * Two hiden layers of three hundred neurons.\n",
    "        * One layer of one hundred neurons.\n",
    "        * One ouput layer of ten neurons, one for each posible number in the dataset (0, 1, ..., 9).\n",
    "    4. Implementation of a cost function and an optimizer for training the neural network.\n",
    "    5. Creation of a model using the training dataset provided.\n",
    "    6. Evaluation of the test dataset set using the model created.\n",
    "- Obtained results highlight the following findings:  \n",
    "    1. Tensorflow permits to create a graph where nodes are operations and edges are information that flows from one operation to others.\n",
    "    2. The variables, constants and placeholders created in Tensorflow not need to be evaluated immediately or in the same machine.\n",
    "    3. There are multiple predefined functions in Tensorflow that can help to create a neural network easily.\n",
    "    4. If the computations were dense, we can distribute the job processing among different computers or gpus using Tensorflow API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
